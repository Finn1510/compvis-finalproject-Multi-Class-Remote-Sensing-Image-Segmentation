{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973e6747",
   "metadata": {},
   "source": [
    "# DDCM-Net: Dense Dilated Convolutions Merging Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb804a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Custom modules\n",
    "from model import create_model, create_trainer\n",
    "from dataset_loader import create_dataloaders\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f03339",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "NUM_CLASSES = 6\n",
    "BACKBONE = 'resnet50'\n",
    "PRETRAINED = True\n",
    "\n",
    "# Class names for visualization\n",
    "CLASS_NAMES = [\n",
    "    'Impervious surfaces',  # 0 - White\n",
    "    'Building',             # 1 - Blue  \n",
    "    'Low vegetation',       # 2 - Cyan\n",
    "    'Tree',                 # 3 - Green\n",
    "    'Car',                  # 4 - Yellow\n",
    "    'Clutter/background'    # 5 - Red\n",
    "]\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    variant='base',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    backbone=BACKBONE,\n",
    "    pretrained=PRETRAINED\n",
    ")\n",
    "\n",
    "# Create trainer wrapper\n",
    "trainer = create_trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    class_names=CLASS_NAMES\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Architecture: DDCM-Net with {BACKBONE} backbone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7bd78",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATA_ROOT = \"./data\"\n",
    "DATASET = \"potsdam\"  # or \"vaihingen\" or \"both\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "PATCH_SIZE = 256\n",
    "STRIDE = 128\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "# Check if data exists\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    print(f\"⚠️  Data directory not found: {DATA_ROOT}\")\n",
    "    print(\"Please ensure you have the ISPRS dataset in the data folder\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"├── potsdam/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"└── vaihingen/\")\n",
    "    print(\"    ├── images/\")\n",
    "    print(\"    └── labels/\")\n",
    "else:\n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        root_dir=DATA_ROOT,\n",
    "        dataset=DATASET,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        stride=STRIDE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {DATASET.upper()}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Train batches: {len(train_loader):,}\")\n",
    "    print(f\"Validation batches: {len(val_loader):,}\")\n",
    "    print(f\"Test batches: {len(test_loader):,}\")\n",
    "    print(f\"Patch size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
    "    \n",
    "    # Show a sample batch\n",
    "    sample_images, sample_labels = next(iter(train_loader))\n",
    "    print(f\"Sample batch shape - Images: {sample_images.shape}, Labels: {sample_labels.shape}\")\n",
    "    print(f\"Classes in sample: {torch.unique(sample_labels).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef9dea",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset samples\n",
    "def visualize_dataset_samples(dataloader, num_samples=4):\n",
    "    \"\"\"Visualize samples from the dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 10))\n",
    "    \n",
    "    # Get a batch\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Get single sample\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        img_denorm = img * std[:, None, None] + mean[:, None, None]\n",
    "        img_denorm = torch.clamp(img_denorm, 0, 1)\n",
    "        \n",
    "        # Plot image\n",
    "        axes[0, i].imshow(img_denorm.permute(1, 2, 0))\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Plot label\n",
    "        im = axes[1, i].imshow(label, cmap='tab10', vmin=0, vmax=5)\n",
    "        axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    # Add colorbar for labels\n",
    "    plt.colorbar(im, ax=axes[1, :], fraction=0.046, pad=0.04, \n",
    "                 ticks=range(6), label='Land Cover Classes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print class statistics\n",
    "    unique_classes = torch.unique(labels)\n",
    "    print(f\"Classes in this batch: {unique_classes.tolist()}\")\n",
    "    for class_id in unique_classes:\n",
    "        class_name = CLASS_NAMES[class_id]\n",
    "        pixel_count = (labels == class_id).sum().item()\n",
    "        percentage = pixel_count / labels.numel() * 100\n",
    "        print(f\"  {class_id}: {class_name} - {pixel_count:,} pixels ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize samples if data is available\n",
    "if 'train_loader' in locals():\n",
    "    print(\"Dataset samples:\")\n",
    "    visualize_dataset_samples(train_loader, num_samples=4)\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please ensure data is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca978b5",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 15 \n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Start training if data is available\n",
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    print(f\"\\nTraining started...\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot start training - dataset not available\")\n",
    "    print(\"Please ensure the data is properly loaded before training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e3778",
   "metadata": {},
   "source": [
    "## 5. Training Visualization and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if 'history' in locals() and trainer.history['train_loss']:\n",
    "    print(\"Training History Visualization\")\n",
    "    \n",
    "    # Plot using trainer's built-in visualization\n",
    "    trainer.plot_training_history(figsize=(18, 6))\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = trainer.history['train_loss'][-1]\n",
    "    final_val_loss = trainer.history['val_loss'][-1]\n",
    "    final_train_acc = trainer.history['train_acc'][-1]\n",
    "    final_val_acc = trainer.history['val_acc'][-1]\n",
    "    final_train_miou = trainer.history['train_miou'][-1]\n",
    "    final_val_miou = trainer.history['val_miou'][-1]\n",
    "    \n",
    "    print(\"\\nFinal Training Metrics:\")\n",
    "    print(f\"  Train Loss: {final_train_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"  Train Acc:  {final_train_acc:.3f} | Val Acc:  {final_val_acc:.3f}\")\n",
    "    print(f\"  Train mIoU: {final_train_miou:.3f} | Val mIoU: {final_val_miou:.3f}\")\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = np.argmax(trainer.history['val_miou']) + 1\n",
    "    best_miou = max(trainer.history['val_miou'])\n",
    "    print(f\"\\nBest Validation mIoU: {best_miou:.3f} (Epoch {best_epoch})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No training history available.\")\n",
    "    print(\"Please run training first or load a pre-trained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d790a",
   "metadata": {},
   "source": [
    "## 6. Model Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88182652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for inference\n",
    "if os.path.exists('best_model.pth'):\n",
    "    print(\"Loading best trained model...\")\n",
    "    trainer.load_model('best_model.pth')\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"No saved model found. Using current model state.\")\n",
    "\n",
    "# Visualize predictions on test data\n",
    "if 'test_loader' in locals():\n",
    "    print(\"\\nModel Predictions Visualization\")\n",
    "    print(\"Comparing ground truth vs predictions on test samples...\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    trainer.visualize_predictions(test_loader, num_samples=4, figsize=(20, 8))\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for prediction visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70584fa",
   "metadata": {},
   "source": [
    "### Detailed Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cadc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation on test set\n",
    "if 'test_loader' in locals():\n",
    "    print(\"Detailed Model Evaluation\")\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    test_losses = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "            test_losses.append(loss.item())\n",
    "    \n",
    "    # Concatenate all results\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_acc = (all_predictions == all_targets).float().mean()\n",
    "    test_loss = np.mean(test_losses)\n",
    "    \n",
    "    print(f\"\\nTest Set Results:\")\n",
    "    print(f\"  Overall Accuracy: {overall_acc:.3f}\")\n",
    "    print(f\"  Average Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Calculate class-wise IoU\n",
    "    class_ious = []\n",
    "    print(f\"\\nClass-wise IoU:\")\n",
    "    for class_id in range(NUM_CLASSES):\n",
    "        pred_mask = (all_predictions == class_id)\n",
    "        target_mask = (all_targets == class_id)\n",
    "        \n",
    "        if target_mask.sum() == 0:\n",
    "            if pred_mask.sum() == 0:\n",
    "                iou = 1.0\n",
    "            else:\n",
    "                iou = 0.0\n",
    "        else:\n",
    "            intersection = (pred_mask & target_mask).float().sum()\n",
    "            union = (pred_mask | target_mask).float().sum()\n",
    "            iou = (intersection / union).item()\n",
    "        \n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {class_id}: {CLASS_NAMES[class_id]:<20} IoU: {iou:.3f}\")\n",
    "    \n",
    "    mean_iou = np.mean(class_ious)\n",
    "    print(f\"\\nMean IoU: {mean_iou:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for detailed evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_map(mask):\n",
    "    \"\"\"\n",
    "    Apply color mapping to segmentation mask.\n",
    "    \n",
    "    Args:\n",
    "        mask: numpy array of shape (H, W) with integer class labels\n",
    "        \n",
    "    Returns:\n",
    "        colored_mask: numpy array of shape (H, W, 3) with RGB colors\n",
    "    \"\"\"\n",
    "    # Define colors for each class (RGB format)\n",
    "    colors = [\n",
    "        [255, 255, 255],  # 0 - White - Impervious surfaces\n",
    "        [0, 0, 255],      # 1 - Blue - Building\n",
    "        [0, 255, 255],    # 2 - Cyan - Low vegetation\n",
    "        [0, 255, 0],      # 3 - Green - Tree\n",
    "        [255, 255, 0],    # 4 - Yellow - Car\n",
    "        [255, 0, 0],      # 5 - Red - Clutter/background\n",
    "    ]\n",
    "    \n",
    "    # Convert colors to numpy array\n",
    "    colors = np.array(colors)\n",
    "    \n",
    "    # Create empty RGB image\n",
    "    h, w = mask.shape\n",
    "    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Apply colors based on class indices\n",
    "    for class_idx in range(len(colors)):\n",
    "        colored_mask[mask == class_idx] = colors[class_idx]\n",
    "    \n",
    "    return colored_mask\n",
    "\n",
    "# Visualize sample predictions with analysis\n",
    "def visualize_predictions_detailed(model, dataloader, num_samples=6):\n",
    "    \"\"\"Enhanced prediction visualization with confidence analysis\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get batch of samples\n",
    "    dataiter = iter(dataloader)\n",
    "    images, targets = next(dataiter)\n",
    "    \n",
    "    # Take subset of samples\n",
    "    images = images[:num_samples]\n",
    "    targets = targets[:num_samples]\n",
    "    \n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        confidence = torch.max(probabilities, dim=1)[0]\n",
    "    \n",
    "    # Move to CPU for visualization\n",
    "    images = images.cpu()\n",
    "    targets = targets.cpu()\n",
    "    predictions = predictions.cpu()\n",
    "    confidence = confidence.cpu()\n",
    "    probabilities = probabilities.cpu()\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        img = np.transpose(images[i], (1, 2, 0))\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        gt_colored = apply_color_map(targets[i].numpy())\n",
    "        axes[i, 1].imshow(gt_colored)\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        pred_colored = apply_color_map(predictions[i].numpy())\n",
    "        axes[i, 2].imshow(pred_colored)\n",
    "        axes[i, 2].set_title(f'Prediction\\nConf: {confidence[i]:.3f}')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Confidence map\n",
    "        conf_map = confidence[i].numpy()\n",
    "        im = axes[i, 3].imshow(conf_map, cmap='hot', vmin=0, vmax=1)\n",
    "        axes[i, 3].set_title('Confidence Map')\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # Add colorbar for confidence\n",
    "        plt.colorbar(im, ax=axes[i, 3], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Class distribution analysis\n",
    "    print(\"\\nPrediction Analysis:\")\n",
    "    for i in range(num_samples):\n",
    "        pred_flat = predictions[i].flatten()\n",
    "        target_flat = targets[i].flatten()\n",
    "        \n",
    "        # Calculate accuracy for this sample\n",
    "        sample_acc = (pred_flat == target_flat).float().mean()\n",
    "        print(f\"\\nSample {i+1} - Accuracy: {sample_acc:.3f}\")\n",
    "        \n",
    "        # Show class distributions\n",
    "        print(\"  Predicted classes:\", np.bincount(pred_flat, minlength=NUM_CLASSES))\n",
    "        print(\"  Ground truth:     \", np.bincount(target_flat, minlength=NUM_CLASSES))\n",
    "\n",
    "# Run detailed prediction visualization\n",
    "print(\"Generating Detailed Prediction Analysis...\")\n",
    "visualize_predictions_detailed(model, test_loader if 'test_loader' in locals() else val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e469977",
   "metadata": {},
   "source": [
    "## Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model state dict\n",
    "model_path = 'models/ddcm_net_trained.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'variant': 'ddcm',\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'input_channels': 3\n",
    "    },\n",
    "    'training_history': history,\n",
    "    'class_names': CLASS_NAMES\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Example of loading the model later\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a trained DDCM-Net model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Recreate model with same config\n",
    "    config = checkpoint['model_config']\n",
    "    loaded_model = DDCMNet(\n",
    "        num_classes=config['num_classes'],\n",
    "        variant=config['variant']\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    loaded_model.to(device)\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from: {model_path}\")\n",
    "    print(f\"Configuration: {config}\")\n",
    "    \n",
    "    return loaded_model, checkpoint['training_history']\n",
    "\n",
    "# Demonstrate loading (commented out to avoid reloading in this session)\n",
    "# loaded_model, loaded_history = load_trained_model(model_path)\n",
    "# print(\"Model successfully reloaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
