{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973e6747",
   "metadata": {},
   "source": [
    "# DDCM-Net: Dense Dilated Convolutions Merging Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb804a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Custom modules\n",
    "from model import create_model, create_trainer\n",
    "from dataset_loader import create_dataloaders\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f03339",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "NUM_CLASSES = 6\n",
    "BACKBONE = 'resnet50'\n",
    "PRETRAINED = True\n",
    "\n",
    "# Class names for visualization\n",
    "CLASS_NAMES = [\n",
    "    'Impervious surfaces',  # 0 - White\n",
    "    'Building',             # 1 - Blue  \n",
    "    'Low vegetation',       # 2 - Cyan\n",
    "    'Tree',                 # 3 - Green\n",
    "    'Car',                  # 4 - Yellow\n",
    "    'Clutter/background'    # 5 - Red\n",
    "]\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    variant='base',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    backbone=BACKBONE,\n",
    "    pretrained=PRETRAINED\n",
    ")\n",
    "\n",
    "# Create trainer wrapper\n",
    "trainer = create_trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    class_names=CLASS_NAMES\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Architecture: DDCM-Net with {BACKBONE} backbone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc6efb",
   "metadata": {},
   "source": [
    "### Load model from a previous training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4786af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.load_model(\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7bd78",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATA_ROOT = \"./data\"\n",
    "DATASET = \"potsdam\"  # or \"vaihingen\" or \"both\"\n",
    "BATCH_SIZE = 5  \n",
    "NUM_WORKERS = 4\n",
    "PATCH_SIZE = 256  \n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "# Check if data exists\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    print(f\"Data directory not found: {DATA_ROOT}\")\n",
    "    print(\"Please ensure you have the ISPRS dataset in the data folder\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"├── potsdam/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"└── vaihingen/\")\n",
    "    print(\"    ├── images/\")\n",
    "    print(\"    └── labels/\")\n",
    "else:\n",
    "    train_loader, val_loader, test_loader, holdout_loader = create_dataloaders(\n",
    "        root_dir=DATA_ROOT,\n",
    "        dataset=DATASET,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {DATASET.upper()}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE} (paper specification)\")\n",
    "    print(f\"Patch size: {PATCH_SIZE}x{PATCH_SIZE} (paper specification)\")\n",
    "    print(f\"Random sampling: 5000 train patches, 1000 val/test patches (paper-compliant)\")\n",
    "    print(f\"Train batches: {len(train_loader):,}\")\n",
    "    print(f\"Validation batches: {len(val_loader):,}\")\n",
    "    print(f\"Test batches: {len(test_loader):,}\")\n",
    "    \n",
    "    # Show a sample batch\n",
    "    # sample_images, sample_labels = next(iter(train_loader))\n",
    "    # print(f\"Sample batch shape - Images: {sample_images.shape}, Labels: {sample_labels.shape}\")\n",
    "    # print(f\"Classes in sample: {torch.unique(sample_labels).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef9dea",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset samples\n",
    "def visualize_dataset_samples(dataloader, num_samples=4):\n",
    "    \"\"\"Visualize samples from the dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 10))\n",
    "    \n",
    "    # Get a batch\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Get single sample\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        img_denorm = img * std[:, None, None] + mean[:, None, None]\n",
    "        img_denorm = torch.clamp(img_denorm, 0, 1)\n",
    "        \n",
    "        # Plot image\n",
    "        axes[0, i].imshow(img_denorm.permute(1, 2, 0))\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Plot label\n",
    "        im = axes[1, i].imshow(label, cmap='tab10', vmin=0, vmax=5)\n",
    "        axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    # Add colorbar for labels\n",
    "    plt.colorbar(im, ax=axes[1, :], fraction=0.046, pad=0.04, \n",
    "                 ticks=range(6), label='Land Cover Classes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print class statistics\n",
    "    unique_classes = torch.unique(labels)\n",
    "    print(f\"Classes in this batch: {unique_classes.tolist()}\")\n",
    "    for class_id in unique_classes:\n",
    "        class_name = CLASS_NAMES[class_id]\n",
    "        pixel_count = (labels == class_id).sum().item()\n",
    "        percentage = pixel_count / labels.numel() * 100\n",
    "        print(f\"  {class_id}: {class_name} - {pixel_count:,} pixels ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize samples if data is available\n",
    "if 'train_loader' in locals():\n",
    "    print(\"Dataset samples:\")\n",
    "    visualize_dataset_samples(train_loader, num_samples=4)\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please ensure data is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca978b5",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 6.01e-5 # 8.5e-5/√2\n",
    "WEIGHT_DECAY = 2e-5\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Start training if data is available\n",
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    print(f\"\\nTraining started...\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        use_mfb=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot start training - dataset not available\")\n",
    "    print(\"Please ensure the data is properly loaded before training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e3778",
   "metadata": {},
   "source": [
    "## 5. Training Visualization and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if 'history' in locals() and trainer.history['train_loss']:\n",
    "    print(\"Training History Visualization\")\n",
    "    \n",
    "    # Plot using trainer's built-in visualization\n",
    "    trainer.plot_training_history(figsize=(18, 6))\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = trainer.history['train_loss'][-1]\n",
    "    final_val_loss = trainer.history['val_loss'][-1]\n",
    "    final_train_acc = trainer.history['train_acc'][-1]\n",
    "    final_val_acc = trainer.history['val_acc'][-1]\n",
    "    final_train_miou = trainer.history['train_miou'][-1]\n",
    "    final_val_miou = trainer.history['val_miou'][-1]\n",
    "    \n",
    "    print(\"\\nFinal Training Metrics:\")\n",
    "    print(f\"  Train Loss: {final_train_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"  Train Acc:  {final_train_acc:.3f} | Val Acc:  {final_val_acc:.3f}\")\n",
    "    print(f\"  Train mIoU: {final_train_miou:.3f} | Val mIoU: {final_val_miou:.3f}\")\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = np.argmax(trainer.history['val_miou']) + 1\n",
    "    best_miou = max(trainer.history['val_miou'])\n",
    "    print(f\"\\nBest Validation mIoU: {best_miou:.3f} (Epoch {best_epoch})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No training history available.\")\n",
    "    print(\"Please run training first or load a pre-trained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d790a",
   "metadata": {},
   "source": [
    "## 6. Model Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88182652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for inference\n",
    "if os.path.exists('best_model.pth'):\n",
    "    print(\"Loading best trained model...\")\n",
    "    trainer.load_model('best_model.pth')\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"No saved model found. Using current model state.\")\n",
    "\n",
    "# Visualize predictions on test data\n",
    "if 'test_loader' in locals():\n",
    "    print(\"\\nModel Predictions Visualization\")\n",
    "    print(\"Comparing ground truth vs predictions on test samples...\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    trainer.visualize_predictions(test_loader, num_samples=4, figsize=(20, 8))\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for prediction visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70584fa",
   "metadata": {},
   "source": [
    "### Detailed Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cadc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation on test set\n",
    "if 'test_loader' in locals():\n",
    "    print(\"Detailed Model Evaluation\")\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    # Initialize confusion matrix for class-wise metrics\n",
    "    num_classes = NUM_CLASSES\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    total_pixels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            with torch.no_grad():  \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            pred_flat = predictions.reshape(-1)\n",
    "            target_flat = targets.reshape(-1)\n",
    "            \n",
    "            # Update histogram\n",
    "            for t in range(num_classes):\n",
    "                mask = (target_flat == t)\n",
    "                if mask.sum() > 0:\n",
    "                    p = pred_flat[mask]\n",
    "                    bincount = torch.bincount(p, minlength=num_classes)\n",
    "                    confusion_matrix[t] += bincount\n",
    "            \n",
    "            total_pixels += targets.numel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss /= total_pixels\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    overall_acc = torch.diag(confusion_matrix).sum() / confusion_matrix.sum()\n",
    "    \n",
    "    print(f\"\\nTest Set Results:\")\n",
    "    print(f\"  Overall Accuracy: {overall_acc.item():.3f}\")\n",
    "    print(f\"  Average Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Calculate class-wise IoU\n",
    "    class_ious = []\n",
    "    print(f\"\\nClass-wise IoU:\")\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        # True positives: diagonal elements of the confusion matrix\n",
    "        tp = confusion_matrix[class_id, class_id].item()\n",
    "        \n",
    "        # Sum over row and column for class i\n",
    "        # Row sum = all actual instances of class i\n",
    "        # Column sum = all predicted instances of class i\n",
    "        row_sum = confusion_matrix[class_id, :].sum().item()\n",
    "        col_sum = confusion_matrix[:, class_id].sum().item()\n",
    "        \n",
    "        # IoU = TP / (TP + FP + FN) = TP / (row_sum + col_sum - TP)\n",
    "        denominator = row_sum + col_sum - tp\n",
    "        iou = tp / denominator if denominator > 0 else 0.0\n",
    "        \n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {class_id}: {CLASS_NAMES[class_id]:<20} IoU: {iou:.3f}\")\n",
    "    \n",
    "    mean_iou = sum(class_ious) / len(class_ious)\n",
    "    print(f\"\\nMean IoU: {mean_iou:.3f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    confusion_norm = confusion_matrix / confusion_matrix.sum(dim=1, keepdim=True)\n",
    "    confusion_np = confusion_norm.cpu().numpy()\n",
    "    \n",
    "    sns.heatmap(confusion_np, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for detailed evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e469977",
   "metadata": {},
   "source": [
    "## Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model state dict\n",
    "model_path = 'models/ddcm_net_trained82.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'training_history': history,\n",
    "    'class_names': CLASS_NAMES\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c63cab",
   "metadata": {},
   "source": [
    "### Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8efcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_trained_model(model_path):\n",
    "#     \"\"\"Load a trained DDCM-Net model\"\"\"\n",
    "#     checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "#     # Recreate model with same config\n",
    "#     config = checkpoint['model_config']\n",
    "#     loaded_model = DDCMNet(\n",
    "#         num_classes=config['num_classes'],\n",
    "#         variant=config['variant']\n",
    "#     )\n",
    "    \n",
    "#     # Load weights\n",
    "#     loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     loaded_model.to(device)\n",
    "#     loaded_model.eval()\n",
    "    \n",
    "#     print(f\"Model loaded from: {model_path}\")\n",
    "#     print(f\"Configuration: {config}\")\n",
    "    \n",
    "#     return loaded_model, checkpoint['training_history']\n",
    "\n",
    "# model_path = '/models/ddcm_net_trained.pth'\n",
    "# model, history = load_trained_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
