{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973e6747",
   "metadata": {},
   "source": [
    "# DDCM-Net: Dense Dilated Convolutions Merging Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb804a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model import create_model, create_trainer\n",
    "from dataset_loader import create_dataloaders\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f03339",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "NUM_CLASSES = 6\n",
    "BACKBONE = 'resnet50'\n",
    "PRETRAINED = True\n",
    "\n",
    "# Class names for visualization\n",
    "CLASS_NAMES = [\n",
    "    'Impervious surfaces',  # 0 - White\n",
    "    'Building',             # 1 - Blue  \n",
    "    'Low vegetation',       # 2 - Cyan\n",
    "    'Tree',                 # 3 - Green\n",
    "    'Car',                  # 4 - Yellow\n",
    "    'Clutter/background'    # 5 - Red\n",
    "]\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    variant='base',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    backbone=BACKBONE,\n",
    "    pretrained=PRETRAINED\n",
    ")\n",
    "\n",
    "# Create trainer wrapper\n",
    "trainer = create_trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    class_names=CLASS_NAMES\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Architecture: DDCM-Net with {BACKBONE} backbone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc6efb",
   "metadata": {},
   "source": [
    "### Load model from a previous training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4786af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = trainer.load_model(\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7bd78",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATA_ROOT = \"./data\"\n",
    "DATASET = \"potsdam\"  # or \"vaihingen\" or \"both\"\n",
    "BATCH_SIZE = 5  \n",
    "NUM_WORKERS = 4\n",
    "PATCH_SIZE = 256  \n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "# Check if data exists\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    print(f\"Data directory not found: {DATA_ROOT}\")\n",
    "    print(\"Please ensure you have the ISPRS dataset in the data folder\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"├── potsdam/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"└── vaihingen/\")\n",
    "    print(\"    ├── images/\")\n",
    "    print(\"    └── labels/\")\n",
    "else:\n",
    "    train_loader, val_loader, test_loader, holdout_loader = create_dataloaders(\n",
    "        root_dir=DATA_ROOT,\n",
    "        dataset=DATASET,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {DATASET.upper()}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Patch size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
    "    print(f\"Train batches: {len(train_loader):,}\")\n",
    "    print(f\"Validation batches: {len(val_loader):,}\")\n",
    "    print(f\"Test batches: {len(test_loader):,}\")\n",
    "    \n",
    "    # Show a sample batch\n",
    "    # sample_images, sample_labels = next(iter(train_loader))\n",
    "    # print(f\"Sample batch shape - Images: {sample_images.shape}, Labels: {sample_labels.shape}\")\n",
    "    # print(f\"Classes in sample: {torch.unique(sample_labels).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef9dea",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset samples\n",
    "def visualize_dataset_samples(dataloader, num_samples=4):\n",
    "    \"\"\"Visualize samples from the dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 10))\n",
    "    \n",
    "    # Get a batch\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Get single sample\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        img_denorm = img * std[:, None, None] + mean[:, None, None]\n",
    "        img_denorm = torch.clamp(img_denorm, 0, 1)\n",
    "        \n",
    "        # Plot image\n",
    "        axes[0, i].imshow(img_denorm.permute(1, 2, 0))\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Plot label\n",
    "        im = axes[1, i].imshow(label, cmap='tab10', vmin=0, vmax=5)\n",
    "        axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print class statistics\n",
    "    unique_classes = torch.unique(labels)\n",
    "    print(f\"Classes in this batch: {unique_classes.tolist()}\")\n",
    "    for class_id in unique_classes:\n",
    "        class_name = CLASS_NAMES[class_id]\n",
    "        pixel_count = (labels == class_id).sum().item()\n",
    "        percentage = pixel_count / labels.numel() * 100\n",
    "        print(f\"  {class_id}: {class_name} - {pixel_count:,} pixels ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize samples if data is available\n",
    "if 'train_loader' in locals():\n",
    "    print(\"Dataset samples:\")\n",
    "    visualize_dataset_samples(train_loader, num_samples=4)\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please ensure data is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca978b5",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7a37ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing class frequencies: 100%|██████████| 1000/1000 [05:16<00:00,  3.16it/s]\n",
      "Computing class frequencies: 100%|██████████| 1000/1000 [05:16<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: [0.3154688  0.24464083 0.23769112 0.14688781 0.01443058 0.04088106]\n",
      "Median frequency: 0.146888\n",
      "Class weights: [ 0.46561757  0.60042226  0.6179777   0.9999999  10.178922    3.5930521 ]\n",
      "Using dual LR scheduling: per-iteration polynomial + per-epoch StepLR\n",
      "Training on cuda\n",
      "Model parameters: 9,992,628\n",
      "Dual LR mode: per-iteration polynomial (lr=6.01e-05) + per-epoch StepLR (γ=0.85, step=15)\n",
      "Using pixel-weighted averaging (matches paper implementation)\n",
      "\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Train the model with paper-exact configuration\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_mfb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Will be overridden by use_dual_lr\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_dual_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_DUAL_LR\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot start training - dataset not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\_Dev\\compvis-finalproject\\model.py:454\u001b[0m, in \u001b[0;36mDDCMTrainer.fit\u001b[1;34m(self, train_loader, val_loader, epochs, lr, weight_decay, class_weights, use_mfb, lr_scheduler, use_dual_lr)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# Train with dual LR support\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_dual_lr:\n\u001b[1;32m--> 454\u001b[0m     train_loss, train_acc, train_miou, curr_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_batch_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_dual_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     train_loss, train_acc, train_miou, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch(\n\u001b[0;32m    461\u001b[0m         train_loader, optimizer, criterion, scheduler, use_batch_step\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32mc:\\_Dev\\compvis-finalproject\\model.py:302\u001b[0m, in \u001b[0;36mDDCMTrainer.train_epoch\u001b[1;34m(self, train_loader, optimizer, criterion, scheduler, use_batch_step, use_dual_lr, curr_iter, initial_lr, max_iter)\u001b[0m\n\u001b[0;32m    299\u001b[0m train_miou_meter \u001b[38;5;241m=\u001b[39m AverageMeter()\n\u001b[0;32m    301\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, targets \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m    303\u001b[0m     images, targets \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), targets\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    304\u001b[0m     N \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Total pixels (B × H × W)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1492\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1492\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1444\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1445\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1446\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1285\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\flipg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 80\n",
    "LEARNING_RATE = 8.5e-5 / np.sqrt(2)  \n",
    "WEIGHT_DECAY = 2e-5\n",
    "USE_DUAL_LR = True  \n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE:.2e}\")\n",
    "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Start training if data is available\n",
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    print(f\"\\nTraining started...\")\n",
    "        \n",
    "    # Train the model\n",
    "    history = trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        use_mfb=True,\n",
    "        lr_scheduler='step',  # Will be overridden by use_dual_lr\n",
    "        use_dual_lr=USE_DUAL_LR  \n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot start training - dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e3778",
   "metadata": {},
   "source": [
    "## 5. Training Visualization and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if 'history' in locals() and trainer.history['train_loss']:\n",
    "    print(\"Training History Visualization\")\n",
    "    \n",
    "    # Plot using trainer's built-in visualization\n",
    "    trainer.plot_training_history(figsize=(18, 6))\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = trainer.history['train_loss'][-1]\n",
    "    final_val_loss = trainer.history['val_loss'][-1]\n",
    "    final_train_acc = trainer.history['train_acc'][-1]\n",
    "    final_val_acc = trainer.history['val_acc'][-1]\n",
    "    final_train_miou = trainer.history['train_miou'][-1]\n",
    "    final_val_miou = trainer.history['val_miou'][-1]\n",
    "    \n",
    "    print(\"\\nFinal Training Metrics:\")\n",
    "    print(f\"  Train Loss: {final_train_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"  Train Acc:  {final_train_acc:.3f} | Val Acc:  {final_val_acc:.3f}\")\n",
    "    print(f\"  Train mIoU: {final_train_miou:.3f} | Val mIoU: {final_val_miou:.3f}\")\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = np.argmax(trainer.history['val_miou']) + 1\n",
    "    best_miou = max(trainer.history['val_miou'])\n",
    "    print(f\"\\nBest Validation mIoU: {best_miou:.3f} (Epoch {best_epoch})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No training history available.\")\n",
    "    print(\"Please run training first or load a pre-trained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617474b9",
   "metadata": {},
   "source": [
    "## 5.5. Continue Training from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64816604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for continued training\n",
    "CONTINUE_TRAINING = True  # Set to True to enable\n",
    "ADDITIONAL_EPOCHS = 20     \n",
    "LAST_COMPLETED_EPOCH = 1 \n",
    "LEARNING_RATE = 1e-6 \n",
    "WEIGHT_DECAY = 2e-5\n",
    "\n",
    "if CONTINUE_TRAINING:\n",
    "    if 'trainer' in locals() and 'train_loader' in locals() and 'val_loader' in locals():\n",
    "        # Load the saved model\n",
    "        if os.path.exists('best_model.pth'):\n",
    "            print(\"Loading best model for continued training...\")\n",
    "            trainer.load_model('best_model.pth')\n",
    "            \n",
    "            # Show current training state\n",
    "            total_epochs_trained = len(trainer.history['train_loss'])\n",
    "            print(f\"Model has been trained for {total_epochs_trained} epochs\")\n",
    "            \n",
    "            if trainer.history['val_miou']:\n",
    "                current_best = max(trainer.history['val_miou'])\n",
    "                print(f\"Current best validation mIoU: {current_best:.3f}\")\n",
    "            \n",
    "            print(f\"\\nContinuing training for {ADDITIONAL_EPOCHS} more epochs...\")\n",
    "            updated_history = trainer.continue_training(\n",
    "                train_loader=train_loader, \n",
    "                val_loader=val_loader,\n",
    "                additional_epochs=ADDITIONAL_EPOCHS,\n",
    "                current_epoch=LAST_COMPLETED_EPOCH,  # Use this to set the LR correctly\n",
    "                initial_lr=LEARNING_RATE,\n",
    "                weight_decay=WEIGHT_DECAY\n",
    "            )\n",
    "            \n",
    "            # Plot updated training history\n",
    "            print(\"\\nUpdated Training History:\")\n",
    "            trainer.plot_training_history(figsize=(18, 6))\n",
    "            \n",
    "        else:\n",
    "            print(\"No saved model found at 'best_model.pth'!\")\n",
    "            print(\"Please train the model first or check the model path.\")\n",
    "    else:\n",
    "        print(\"Dataloaders not found!\")\n",
    "        print(\"Please ensure 'trainer', 'train_loader', and 'val_loader' are available.\")\n",
    "else:\n",
    "    print(\"Continued training is disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d790a",
   "metadata": {},
   "source": [
    "## 6. Model Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88182652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for inference\n",
    "if os.path.exists('best_model.pth'):\n",
    "    print(\"Loading best trained model...\")\n",
    "    trainer.load_model('best_model.pth')\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"No saved model found. Using current model state.\")\n",
    "\n",
    "# Visualize predictions on test data\n",
    "if 'test_loader' in locals():\n",
    "    print(\"\\nModel Predictions Visualization\")\n",
    "    print(\"Comparing ground truth vs predictions on test samples...\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    trainer.visualize_predictions(test_loader, num_samples=4, figsize=(20, 8))\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for prediction visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70584fa",
   "metadata": {},
   "source": [
    "### Detailed Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cadc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation on test set\n",
    "if 'test_loader' in locals():\n",
    "    print(\"Detailed Model Evaluation\")\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    # Initialize confusion matrix for class-wise metrics\n",
    "    num_classes = NUM_CLASSES\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    total_pixels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            with torch.no_grad():  \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            pred_flat = predictions.reshape(-1)\n",
    "            target_flat = targets.reshape(-1)\n",
    "            \n",
    "            # Update histogram\n",
    "            for t in range(num_classes):\n",
    "                mask = (target_flat == t)\n",
    "                if mask.sum() > 0:\n",
    "                    p = pred_flat[mask]\n",
    "                    bincount = torch.bincount(p, minlength=num_classes)\n",
    "                    confusion_matrix[t] += bincount\n",
    "            \n",
    "            total_pixels += targets.numel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss /= total_pixels\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    overall_acc = torch.diag(confusion_matrix).sum() / confusion_matrix.sum()\n",
    "    \n",
    "    print(f\"\\nTest Set Results:\")\n",
    "    print(f\"  Overall Accuracy: {overall_acc.item():.3f}\")\n",
    "    print(f\"  Average Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Calculate class-wise IoU\n",
    "    class_ious = []\n",
    "    print(f\"\\nClass-wise IoU:\")\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        # True positives: diagonal elements of the confusion matrix\n",
    "        tp = confusion_matrix[class_id, class_id].item()\n",
    "        \n",
    "        # Sum over row and column for class i\n",
    "        # Row sum = all actual instances of class i\n",
    "        # Column sum = all predicted instances of class iF\n",
    "        row_sum = confusion_matrix[class_id, :].sum().item()\n",
    "        col_sum = confusion_matrix[:, class_id].sum().item()\n",
    "        \n",
    "        # IoU = TP / (TP + FP + FN) = TP / (row_sum + col_sum - TP)\n",
    "        denominator = row_sum + col_sum - tp\n",
    "        iou = tp / denominator if denominator > 0 else 0.0\n",
    "        \n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {class_id}: {CLASS_NAMES[class_id]:<20} IoU: {iou:.3f}\")\n",
    "    \n",
    "    mean_iou = sum(class_ious) / len(class_ious)\n",
    "    print(f\"\\nMean IoU: {mean_iou:.3f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    confusion_norm = confusion_matrix / confusion_matrix.sum(dim=1, keepdim=True)\n",
    "    confusion_np = confusion_norm.cpu().numpy()\n",
    "    \n",
    "    sns.heatmap(confusion_np, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Test data not available for detailed evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5a840",
   "metadata": {},
   "source": [
    "# Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff43388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tta_utils import TTAPredictor, TTAEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e469977",
   "metadata": {},
   "source": [
    "## Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model state dict\n",
    "model_path = 'models/ddcm_net_trained85v2tta.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'training_history': history,\n",
    "    'class_names': CLASS_NAMES\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c63cab",
   "metadata": {},
   "source": [
    "### Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8efcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_trained_model(model_path):\n",
    "#     \"\"\"Load a trained DDCM-Net model\"\"\"\n",
    "#     checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "#     # Recreate model with same config\n",
    "#     config = checkpoint['model_config']\n",
    "#     loaded_model = DDCMNet(\n",
    "#         num_classes=config['num_classes'],\n",
    "#         variant=config['variant']\n",
    "#     )\n",
    "    \n",
    "#     # Load weights\n",
    "#     loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     loaded_model.to(device)\n",
    "#     loaded_model.eval()\n",
    "    \n",
    "#     print(f\"Model loaded from: {model_path}\")\n",
    "#     print(f\"Configuration: {config}\")\n",
    "    \n",
    "#     return loaded_model, checkpoint['training_history']\n",
    "\n",
    "# model_path = '/models/ddcm_net_trained.pth'\n",
    "# model, history = load_trained_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179923dd",
   "metadata": {},
   "source": [
    "# Enhanced DDCM-Net with Global Context via Self-Attention\n",
    "\n",
    "This section demonstrates the enhanced DDCM-Net model that integrates transformer-style self-attention blocks to provide global context modeling. The enhancement improves long-range dependency modeling while maintaining computational efficiency through windowed attention mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff090565",
   "metadata": {},
   "source": [
    "## Model Variants Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Enhanced DDCM-Net Model Comparison ===\\n\")\n",
    "\n",
    "# Create different model variants for comparison\n",
    "print(\"1. Creating model variants...\")\n",
    "\n",
    "# Original DDCM-Net\n",
    "model_base = create_model(variant='base', num_classes=NUM_CLASSES, backbone=BACKBONE)\n",
    "base_params = sum(p.numel() for p in model_base.parameters())\n",
    "print(f\"   Base DDCM-Net: {base_params:,} parameters\")\n",
    "\n",
    "# Enhanced DDCM-Net with default global context\n",
    "model_enhanced = create_model(variant='enhanced', num_classes=NUM_CLASSES, backbone=BACKBONE)\n",
    "enhanced_params = sum(p.numel() for p in model_enhanced.parameters())\n",
    "print(f\"   Enhanced DDCM-Net: {enhanced_params:,} parameters (+{enhanced_params - base_params:,})\")\n",
    "\n",
    "# Enhanced DDCM-Net with custom configuration\n",
    "custom_config = {\n",
    "    'num_heads': 8,           # Number of attention heads\n",
    "    'num_layers': 2,          # Number of transformer layers  \n",
    "    'use_windowed': True,     # Use windowed attention for efficiency\n",
    "    'window_size': 7,         # Window size for windowed attention\n",
    "    'dropout': 0.1,           # Dropout rate\n",
    "    'pos_embed': True         # Use positional embeddings\n",
    "}\n",
    "\n",
    "model_custom = create_model(\n",
    "    variant='enhanced', \n",
    "    num_classes=NUM_CLASSES, \n",
    "    backbone=BACKBONE,\n",
    "    global_context_config=custom_config\n",
    ")\n",
    "custom_params = sum(p.numel() for p in model_custom.parameters())\n",
    "print(f\"   Custom Enhanced DDCM-Net: {custom_params:,} parameters\")\n",
    "\n",
    "# Test forward pass compatibility\n",
    "print(f\"\\n2. Testing forward pass compatibility...\")\n",
    "sample_input = torch.randn(2, 3, 512, 512)\n",
    "print(f\"   Input shape: {sample_input.shape}\")\n",
    "\n",
    "model_base.eval()\n",
    "model_enhanced.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_base = model_base(sample_input)\n",
    "    output_enhanced = model_enhanced(sample_input)\n",
    "\n",
    "print(f\"   Base model output: {output_base.shape}\")\n",
    "print(f\"   Enhanced model output: {output_enhanced.shape}\")\n",
    "print(f\"   Output shapes match: {output_base.shape == output_enhanced.shape}\")\n",
    "\n",
    "# Show parameter breakdown\n",
    "print(f\"\\n3. Parameter Analysis...\")\n",
    "parameter_overhead = ((enhanced_params - base_params) / base_params * 100)\n",
    "print(f\"   Parameter overhead: {parameter_overhead:.1f}%\")\n",
    "print(f\"   Additional parameters: {enhanced_params - base_params:,}\")\n",
    "\n",
    "# Show different configuration options\n",
    "print(f\"\\n4. Available Configuration Examples...\")\n",
    "configs = [\n",
    "    {\n",
    "        'name': 'Lightweight (for limited compute)',\n",
    "        'config': {'num_heads': 4, 'num_layers': 1, 'window_size': 7}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Standard (recommended)',\n",
    "        'config': {'num_heads': 8, 'num_layers': 2, 'window_size': 7}\n",
    "    },\n",
    "    {\n",
    "        'name': 'High-capacity (for best accuracy)',\n",
    "        'config': {'num_heads': 8, 'num_layers': 3, 'window_size': 14}\n",
    "    }\n",
    "]\n",
    "\n",
    "for config_info in configs:\n",
    "    name = config_info['name']\n",
    "    config = config_info['config']\n",
    "    \n",
    "    test_model = create_model(\n",
    "        variant='enhanced', \n",
    "        num_classes=NUM_CLASSES,\n",
    "        global_context_config=config\n",
    "    )\n",
    "    params = sum(p.numel() for p in test_model.parameters())\n",
    "    overhead = ((params - base_params) / base_params * 100)\n",
    "    \n",
    "    print(f\"   {name}: {params:,} params (+{overhead:.1f}%)\")\n",
    "\n",
    "print(f\"\\n=== Model variants created successfully! ===\")\n",
    "print(\"The enhanced model is backward compatible and uses the same training interface.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9d3d4",
   "metadata": {},
   "source": [
    "## Enhanced Model Training\n",
    "\n",
    "Now let's train the enhanced model with the same configuration as the base model to compare performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Model Training Configuration\n",
    "TRAIN_ENHANCED = True  # Set to True to train the enhanced model\n",
    "ENHANCED_EPOCHS = 80\n",
    "ENHANCED_LR = 8.5e-5 / np.sqrt(2) \n",
    "ENHANCED_WEIGHT_DECAY = 2e-5\n",
    "USE_ENHANCED_DUAL_LR = True  \n",
    "\n",
    "if TRAIN_ENHANCED:\n",
    "    if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "        print(\"=== Training Enhanced DDCM-Net ===\")\n",
    "        \n",
    "        # Create enhanced model with standard configuration\n",
    "        enhanced_model = create_model(\n",
    "            variant='enhanced',\n",
    "            num_classes=NUM_CLASSES,\n",
    "            backbone=BACKBONE,\n",
    "            pretrained=PRETRAINED,\n",
    "            global_context_config={\n",
    "                'num_heads': 8,\n",
    "                'num_layers': 2,\n",
    "                'use_windowed': True,\n",
    "                'window_size': 7,\n",
    "                'dropout': 0.1,\n",
    "                'pos_embed': True\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Create enhanced trainer\n",
    "        enhanced_trainer = create_trainer(\n",
    "            model=enhanced_model,\n",
    "            device=device,\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        \n",
    "        # Print model comparison\n",
    "        enhanced_params = sum(p.numel() for p in enhanced_model.parameters())\n",
    "        base_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Enhanced model parameters: {enhanced_params:,}\")\n",
    "        print(f\"Base model parameters: {base_params:,}\")\n",
    "        print(f\"Parameter increase: +{enhanced_params - base_params:,} (+{((enhanced_params - base_params) / base_params * 100):.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nStarting enhanced model training...\")\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Epochs: {ENHANCED_EPOCHS}\")\n",
    "        print(f\"  Learning rate: {ENHANCED_LR:.2e}\")\n",
    "        print(f\"  Weight decay: {ENHANCED_WEIGHT_DECAY}\")\n",
    "        print(f\"  Device: {device}\")\n",
    "        \n",
    "        # Train the enhanced model\n",
    "        enhanced_history = enhanced_trainer.fit(\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            epochs=ENHANCED_EPOCHS,\n",
    "            lr=ENHANCED_LR,\n",
    "            weight_decay=ENHANCED_WEIGHT_DECAY,\n",
    "            use_mfb=True,\n",
    "            lr_scheduler='step',  # Will be overridden by use_dual_lr\n",
    "            use_dual_lr=USE_ENHANCED_DUAL_LR \n",
    "        )\n",
    "        \n",
    "        # Save enhanced model with different name\n",
    "        enhanced_trainer.save_model('best_enhanced_model.pth')\n",
    "        print(\"Enhanced model saved as 'best_enhanced_model.pth'\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Cannot start enhanced training - dataset not available\")\n",
    "else:\n",
    "    print(\"Enhanced model training is disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79699ef4",
   "metadata": {},
   "source": [
    "### Enhanced Model Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot enhanced model training history and compare with base model\n",
    "if 'enhanced_history' in locals() and enhanced_trainer.history['train_loss']:\n",
    "    print(\"Enhanced Model Training History Visualization\")\n",
    "    \n",
    "    # Plot enhanced training history\n",
    "    enhanced_trainer.plot_training_history(figsize=(18, 6))\n",
    "    \n",
    "    # Print final enhanced metrics\n",
    "    final_enhanced_train_loss = enhanced_trainer.history['train_loss'][-1]\n",
    "    final_enhanced_val_loss = enhanced_trainer.history['val_loss'][-1]\n",
    "    final_enhanced_train_acc = enhanced_trainer.history['train_acc'][-1]\n",
    "    final_enhanced_val_acc = enhanced_trainer.history['val_acc'][-1]\n",
    "    final_enhanced_train_miou = enhanced_trainer.history['train_miou'][-1]\n",
    "    final_enhanced_val_miou = enhanced_trainer.history['val_miou'][-1]\n",
    "    \n",
    "    print(\"\\nFinal Enhanced Model Metrics:\")\n",
    "    print(f\"  Train Loss: {final_enhanced_train_loss:.4f} | Val Loss: {final_enhanced_val_loss:.4f}\")\n",
    "    print(f\"  Train Acc:  {final_enhanced_train_acc:.3f} | Val Acc:  {final_enhanced_val_acc:.3f}\")\n",
    "    print(f\"  Train mIoU: {final_enhanced_train_miou:.3f} | Val mIoU: {final_enhanced_val_miou:.3f}\")\n",
    "    \n",
    "    # Find best epoch for enhanced model\n",
    "    best_enhanced_epoch = np.argmax(enhanced_trainer.history['val_miou']) + 1\n",
    "    best_enhanced_miou = max(enhanced_trainer.history['val_miou'])\n",
    "    print(f\"\\nBest Enhanced Validation mIoU: {best_enhanced_miou:.3f} (Epoch {best_enhanced_epoch})\")\n",
    "    \n",
    "    # Compare with base model if available\n",
    "    if 'trainer' in locals() and trainer.history['val_miou']:\n",
    "        base_best_miou = max(trainer.history['val_miou'])\n",
    "        improvement = best_enhanced_miou - base_best_miou\n",
    "        print(f\"\\nModel Comparison:\")\n",
    "        print(f\"  Base Model Best mIoU: {base_best_miou:.3f}\")\n",
    "        print(f\"  Enhanced Model Best mIoU: {best_enhanced_miou:.3f}\")\n",
    "        print(f\"  Improvement: {improvement:+.3f} ({(improvement/base_best_miou*100):+.1f}%)\")\n",
    "        \n",
    "        # Side-by-side training curves comparison\n",
    "        if len(trainer.history['val_miou']) > 0 and len(enhanced_trainer.history['val_miou']) > 0:\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
    "            \n",
    "            # Get epochs for both models\n",
    "            base_epochs = range(1, len(trainer.history['train_loss']) + 1)\n",
    "            enhanced_epochs = range(1, len(enhanced_trainer.history['train_loss']) + 1)\n",
    "            \n",
    "            # Loss comparison\n",
    "            axes[0].plot(base_epochs, trainer.history['train_loss'], 'b-', label='Base Train', linewidth=2)\n",
    "            axes[0].plot(base_epochs, trainer.history['val_loss'], 'b--', label='Base Val', linewidth=2)\n",
    "            axes[0].plot(enhanced_epochs, enhanced_trainer.history['train_loss'], 'r-', label='Enhanced Train', linewidth=2)\n",
    "            axes[0].plot(enhanced_epochs, enhanced_trainer.history['val_loss'], 'r--', label='Enhanced Val', linewidth=2)\n",
    "            axes[0].set_title('Loss Comparison')\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Accuracy comparison\n",
    "            axes[1].plot(base_epochs, trainer.history['train_acc'], 'b-', label='Base Train', linewidth=2)\n",
    "            axes[1].plot(base_epochs, trainer.history['val_acc'], 'b--', label='Base Val', linewidth=2)\n",
    "            axes[1].plot(enhanced_epochs, enhanced_trainer.history['train_acc'], 'r-', label='Enhanced Train', linewidth=2)\n",
    "            axes[1].plot(enhanced_epochs, enhanced_trainer.history['val_acc'], 'r--', label='Enhanced Val', linewidth=2)\n",
    "            axes[1].set_title('Accuracy Comparison')\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Accuracy')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # mIoU comparison\n",
    "            axes[2].plot(base_epochs, trainer.history['train_miou'], 'b-', label='Base Train', linewidth=2)\n",
    "            axes[2].plot(base_epochs, trainer.history['val_miou'], 'b--', label='Base Val', linewidth=2)\n",
    "            axes[2].plot(enhanced_epochs, enhanced_trainer.history['train_miou'], 'r-', label='Enhanced Train', linewidth=2)\n",
    "            axes[2].plot(enhanced_epochs, enhanced_trainer.history['val_miou'], 'r--', label='Enhanced Val', linewidth=2)\n",
    "            axes[2].set_title('mIoU Comparison')\n",
    "            axes[2].set_xlabel('Epoch')\n",
    "            axes[2].set_ylabel('mIoU')\n",
    "            axes[2].legend()\n",
    "            axes[2].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No enhanced training history available.\")\n",
    "    print(\"Please run enhanced training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7b03b",
   "metadata": {},
   "source": [
    "## Test Time Augmentation (TTA) Comparison\n",
    "\n",
    "Now let's compare both the base and enhanced models using Test Time Augmentation to see the performance differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6316b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TTA utilities\n",
    "from tta_utils import TTAEvaluator, load_model_for_tta\n",
    "\n",
    "print(\"=== Test Time Augmentation Model Comparison ===\\n\")\n",
    "\n",
    "# TTA Configuration\n",
    "RUN_TTA_COMPARISON = True  # Set to True to enable TTA comparison\n",
    "MAX_TTA_IMAGES = 3         # Limit images for faster demonstration\n",
    "TTA_PATCH_SIZE = 448       \n",
    "TTA_STRIDE = 100           \n",
    "TTA_VISUALIZE = True       # Show visualizations for each image\n",
    "\n",
    "if RUN_TTA_COMPARISON:\n",
    "    if 'test_loader' in locals():\n",
    "        print(\"Preparing models for TTA comparison...\")\n",
    "        \n",
    "        # Create TTA evaluator\n",
    "        tta_evaluator = TTAEvaluator(class_names=CLASS_NAMES)\n",
    "        \n",
    "        # Prepare models dictionary\n",
    "        models_to_compare = {}\n",
    "        \n",
    "        # Add base model (current trained model)\n",
    "        if 'trainer' in locals() and os.path.exists('best_model.pth'):\n",
    "            print(\"Loading base model...\")\n",
    "            base_model_for_tta = load_model_for_tta(\n",
    "                'best_model.pth', \n",
    "                variant='base', \n",
    "                num_classes=NUM_CLASSES, \n",
    "                backbone=BACKBONE,\n",
    "                device=device\n",
    "            )\n",
    "            models_to_compare['Base DDCM-Net'] = base_model_for_tta\n",
    "        \n",
    "        # Add enhanced model if available\n",
    "        if 'enhanced_trainer' in locals() and os.path.exists('best_enhanced_model.pth'):\n",
    "            print(\"Loading enhanced model...\")\n",
    "            enhanced_model_for_tta = load_model_for_tta(\n",
    "                'best_enhanced_model.pth',\n",
    "                variant='enhanced',\n",
    "                num_classes=NUM_CLASSES,\n",
    "                backbone=BACKBONE,\n",
    "                device=device\n",
    "            )\n",
    "            models_to_compare['Enhanced DDCM-Net'] = enhanced_model_for_tta\n",
    "        elif 'enhanced_model' in locals():\n",
    "            print(\"Using current enhanced model...\")\n",
    "            models_to_compare['Enhanced DDCM-Net'] = enhanced_model\n",
    "        \n",
    "        if len(models_to_compare) > 0:\n",
    "            print(f\"Models to compare: {list(models_to_compare.keys())}\")\n",
    "            print(f\"TTA Configuration:\")\n",
    "            print(f\"  Patch size: {TTA_PATCH_SIZE}×{TTA_PATCH_SIZE}\")\n",
    "            print(f\"  Stride: {TTA_STRIDE} pixels\")\n",
    "            print(f\"  Max images: {MAX_TTA_IMAGES}\")\n",
    "            print(f\"  Visualizations: {'Enabled' if TTA_VISUALIZE else 'Disabled'}\")\n",
    "            \n",
    "            # Run TTA comparison\n",
    "            comparison_results = tta_evaluator.compare_models_with_tta(\n",
    "                models_dict=models_to_compare,\n",
    "                test_loader=test_loader,\n",
    "                max_images=MAX_TTA_IMAGES,\n",
    "                visualize=TTA_VISUALIZE,\n",
    "                patch_size=TTA_PATCH_SIZE,\n",
    "                stride=TTA_STRIDE\n",
    "            )\n",
    "            \n",
    "            print(\"\\n=== TTA Comparison Complete ===\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No trained models available for TTA comparison.\")\n",
    "            print(\"Please train at least one model first.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Test loader not available.\")\n",
    "        print(\"Please run the dataset loading cells first to enable TTA evaluation.\")\n",
    "else:\n",
    "    print(\"TTA comparison is disabled.\")\n",
    "    print(\"Set RUN_TTA_COMPARISON = True to enable TTA model comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4c6b3",
   "metadata": {},
   "source": [
    "### TTA Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900181e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and visualize TTA comparison results\n",
    "if 'comparison_results' in locals() and comparison_results:\n",
    "    print(\"=== TTA Results Analysis ===\\n\")\n",
    "    \n",
    "    # Extract model names and results\n",
    "    model_names = list(comparison_results.keys())\n",
    "    \n",
    "    if len(model_names) >= 2:\n",
    "        # Create comprehensive comparison visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        models_data = []\n",
    "        for model_name in model_names:\n",
    "            results = comparison_results[model_name]\n",
    "            models_data.append({\n",
    "                'name': model_name,\n",
    "                'reg_accs': results['all_reg_accuracies'],\n",
    "                'tta_accs': results['all_tta_accuracies'],\n",
    "                'reg_ious': results['all_reg_ious'],\n",
    "                'tta_ious': results['all_tta_ious'],\n",
    "                'avg_reg_acc': results['avg_reg_acc'],\n",
    "                'avg_tta_acc': results['avg_tta_acc'],\n",
    "                'avg_reg_miou': results['avg_reg_miou'],\n",
    "                'avg_tta_miou': results['avg_tta_miou']\n",
    "            })\n",
    "        \n",
    "        # Plot 1: Accuracy comparison per image\n",
    "        for i, model_data in enumerate(models_data):\n",
    "            x_positions = range(len(model_data['reg_accs']))\n",
    "            axes[0, 0].scatter([x + i*0.1 for x in x_positions], model_data['reg_accs'], \n",
    "                              alpha=0.7, label=f\"{model_data['name']} Regular\", marker='o')\n",
    "            axes[0, 0].scatter([x + i*0.1 for x in x_positions], model_data['tta_accs'], \n",
    "                              alpha=0.7, label=f\"{model_data['name']} TTA\", marker='^')\n",
    "        \n",
    "        axes[0, 0].set_xlabel('Image Index')\n",
    "        axes[0, 0].set_ylabel('Accuracy')\n",
    "        axes[0, 0].set_title('Accuracy Comparison Across Images')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: mIoU comparison per image\n",
    "        for i, model_data in enumerate(models_data):\n",
    "            x_positions = range(len(model_data['reg_ious']))\n",
    "            axes[0, 1].scatter([x + i*0.1 for x in x_positions], model_data['reg_ious'], \n",
    "                              alpha=0.7, label=f\"{model_data['name']} Regular\", marker='o')\n",
    "            axes[0, 1].scatter([x + i*0.1 for x in x_positions], model_data['tta_ious'], \n",
    "                              alpha=0.7, label=f\"{model_data['name']} TTA\", marker='^')\n",
    "        \n",
    "        axes[0, 1].set_xlabel('Image Index')\n",
    "        axes[0, 1].set_ylabel('mIoU')\n",
    "        axes[0, 1].set_title('mIoU Comparison Across Images')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Average performance comparison (bar chart)\n",
    "        x_pos = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        reg_accs = [model_data['avg_reg_acc'] for model_data in models_data]\n",
    "        tta_accs = [model_data['avg_tta_acc'] for model_data in models_data]\n",
    "        \n",
    "        bars1 = axes[1, 0].bar([x - width/2 for x in x_pos], reg_accs, width, label='Regular', alpha=0.8)\n",
    "        bars2 = axes[1, 0].bar([x + width/2 for x in x_pos], tta_accs, width, label='TTA', alpha=0.8)\n",
    "        \n",
    "        axes[1, 0].set_xlabel('Model')\n",
    "        axes[1, 0].set_ylabel('Average Accuracy')\n",
    "        axes[1, 0].set_title('Average Accuracy Comparison')\n",
    "        axes[1, 0].set_xticks(x_pos)\n",
    "        axes[1, 0].set_xticklabels(model_names)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars1 + bars2:\n",
    "            height = bar.get_height()\n",
    "            axes[1, 0].annotate(f'{height:.3f}',\n",
    "                               xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                               xytext=(0, 3),  # 3 points vertical offset\n",
    "                               textcoords=\"offset points\",\n",
    "                               ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Plot 4: Average mIoU comparison (bar chart)\n",
    "        reg_ious = [model_data['avg_reg_miou'] for model_data in models_data]\n",
    "        tta_ious = [model_data['avg_tta_miou'] for model_data in models_data]\n",
    "        \n",
    "        bars3 = axes[1, 1].bar([x - width/2 for x in x_pos], reg_ious, width, label='Regular', alpha=0.8)\n",
    "        bars4 = axes[1, 1].bar([x + width/2 for x in x_pos], tta_ious, width, label='TTA', alpha=0.8)\n",
    "        \n",
    "        axes[1, 1].set_xlabel('Model')\n",
    "        axes[1, 1].set_ylabel('Average mIoU')\n",
    "        axes[1, 1].set_title('Average mIoU Comparison')\n",
    "        axes[1, 1].set_xticks(x_pos)\n",
    "        axes[1, 1].set_xticklabels(model_names)\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars3 + bars4:\n",
    "            height = bar.get_height()\n",
    "            axes[1, 1].annotate(f'{height:.3f}',\n",
    "                               xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                               xytext=(0, 3),  # 3 points vertical offset\n",
    "                               textcoords=\"offset points\",\n",
    "                               ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed comparison\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DETAILED COMPARISON ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, model_data in enumerate(models_data):\n",
    "            print(f\"\\n{model_data['name']}:\")\n",
    "            print(f\"  Regular -> TTA Accuracy: {model_data['avg_reg_acc']:.4f} -> {model_data['avg_tta_acc']:.4f} \"\n",
    "                  f\"(+{model_data['avg_tta_acc'] - model_data['avg_reg_acc']:.4f})\")\n",
    "            print(f\"  Regular -> TTA mIoU: {model_data['avg_reg_miou']:.4f} -> {model_data['avg_tta_miou']:.4f} \"\n",
    "                  f\"(+{model_data['avg_tta_miou'] - model_data['avg_reg_miou']:.4f})\")\n",
    "        \n",
    "        # Compare models against each other\n",
    "        if len(models_data) == 2:\n",
    "            base_model = models_data[0]\n",
    "            enhanced_model = models_data[1]\n",
    "            \n",
    "            print(f\"\\n\" + \"=\"*40)\n",
    "            print(f\"MODEL vs MODEL COMPARISON\")\n",
    "            print(f\"=\"*40)\n",
    "            \n",
    "            # Regular prediction comparison\n",
    "            reg_acc_diff = enhanced_model['avg_reg_acc'] - base_model['avg_reg_acc']\n",
    "            reg_miou_diff = enhanced_model['avg_reg_miou'] - base_model['avg_reg_miou']\n",
    "            \n",
    "            print(f\"Regular Prediction Comparison:\")\n",
    "            print(f\"  Accuracy: {enhanced_model['name']} vs {base_model['name']} = {reg_acc_diff:+.4f}\")\n",
    "            print(f\"  mIoU: {enhanced_model['name']} vs {base_model['name']} = {reg_miou_diff:+.4f}\")\n",
    "            \n",
    "            # TTA prediction comparison\n",
    "            tta_acc_diff = enhanced_model['avg_tta_acc'] - base_model['avg_tta_acc']\n",
    "            tta_miou_diff = enhanced_model['avg_tta_miou'] - base_model['avg_tta_miou']\n",
    "            \n",
    "            print(f\"\\nTTA Prediction Comparison:\")\n",
    "            print(f\"  Accuracy: {enhanced_model['name']} vs {base_model['name']} = {tta_acc_diff:+.4f}\")\n",
    "            print(f\"  mIoU: {enhanced_model['name']} vs {base_model['name']} = {tta_miou_diff:+.4f}\")\n",
    "            \n",
    "            # Overall assessment\n",
    "            print(f\"\\nOverall Assessment:\")\n",
    "            if tta_acc_diff > 0 and tta_miou_diff > 0:\n",
    "                print(f\"✓ Enhanced model shows improvement in both accuracy and mIoU with TTA\")\n",
    "            elif tta_acc_diff > 0 or tta_miou_diff > 0:\n",
    "                print(f\"~ Enhanced model shows mixed results compared to base model\")\n",
    "            else:\n",
    "                print(f\"- Enhanced model does not show clear improvement with TTA\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Only {len(model_names)} model(s) available for comparison.\")\n",
    "        print(\"Need at least 2 models for comprehensive comparison.\")\n",
    "\n",
    "else:\n",
    "    print(\"No TTA comparison results available.\")\n",
    "    print(\"Please run the TTA comparison first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
